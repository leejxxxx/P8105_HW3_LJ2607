---
title: "P8105-HW3-lj2607"
author: "Li Jiang"
date: "2024-10-11"
output: github-document
---

```{r}
#load the required packages
library(tidyverse)
library(lubridate)
library(readxl)
library(stringr)
```

Problem1

```{r}
#load the required dataset
library(p8105.datasets)
data("ny_noaa")

#view the dataset
head(ny_noaa)
```

```{r}
#Data cleaning
ny_noaa_df = ny_noaa %>%
  janitor::clean_names()%>%
  drop_na() %>%
  mutate(
    year = year(date), 
    month = month(date),
    day = day(date),
    tmin = as.numeric(tmin) / 10,
    tmax = as.numeric(tmax) / 10,
    prcp = as.numeric(prcp),
    snowfall = as.numeric(snow)
)

#look at the data
view(ny_noaa_df)
```

```{r}
#Checking the most common value in snowfall
snowfall_table <- table(ny_noaa_df$snowfall)%>% 
  sort(snowfall_table, decreasing = TRUE)

view(snowfall_table)

#create histogram for better visualization
ggplot(ny_noaa_df,aes(x = snowfall))+geom_histogram()

```

0 is the most commonly observed value for snowfall. This actually makes sense because it usually snows during winter, which leads 0 value to be of highest frequency in dataset.

```{r}
#two-panel plot showing the average max temperature in Jan and Jul in each station across years
ny_noaa_clean <- ny_noaa_df %>%
  filter(month %in% c(1, 7)) %>% 
  select(id, year, month) %>% 
  mutate(mean_tmax = mean(ny_noaa_df$tmax, na.rm = TRUE))
```


```{r}
ggplot(ny_noaa_clean,aes(x = year, y = mean_tmax, color = id)) +
  geom_point(show.legend = F) +
  facet_grid(. ~ month)
```

#Problem 2

```{r}
#Import dataset accelerometer 
accelerometer <- read.csv("Problem2/nhanes_accel.csv")%>%
  janitor::clean_names()
View(accelerometer)
```

```{r}
#Import dataset demographic
demo <- read.csv("Problem2/nhanes_covar.csv",skip = 4,na = c("NA", "", "."))%>%
  janitor::clean_names()
view(demo)
```

```{r}
#Merge two datasets
participants <- left_join(accelerometer,demo, by = 'seqn')
view(participants)
```

```{r}
#data cleaning
participants_clean <- participants %>%
  relocate(sex,age,bmi,education,.before = min1)%>%
  filter(age >= 21) %>%
  drop_na(sex,age,bmi,education)%>%
  mutate(
    sex = factor(sex, levels = c(1, 2), labels = c("Male", "Female")),
    education = factor(education, levels = c(1, 2, 3), labels = c("Less than high school", "High school equivalent", "More than high school")),
    age = as.numeric(age),
    bmi = as.numeric(bmi))
```

```{r}
#table for men and women in each education category
sex_distribution <- participants_clean%>%
  group_by(education, sex) %>%
  summarize(count = n())

sex_distribution_table <- pivot_wider(
  sex_distribution,
  names_from = sex,
  values_from = count,
  values_fill = list(count = 0))

knitr::kable(sex_distribution)
```


```{r}
#age distribution in each education category
age_distribution <- participants_clean%>%
  group_by(education, sex, age)%>%
  select(education, sex, age)

ggplot(age_distribution, aes(x = age, fill = sex)) +
  geom_histogram(binwidth = 5, position = "dodge", alpha = 0.7) +
  facet_wrap(~ education) +
  labs(title = "Age Distribution by Sex in Each Education Category",
       x = "Age",
       y = "Count")
```

```{r}
#Plot total activity against age in each education category
total_activity <- participants_clean%>%
  mutate(
    total_activity = rowSums(select(., starts_with("min")), na.rm = TRUE))%>%
  relocate(total_activity,.before = min1)%>%
  select(seqn,sex,age,education,total_activity)


ggplot(total_activity, aes(x = age,y = total_activity, color = sex)) +
  geom_smooth(se = FALSE)+
  geom_point(size = 2, position = position_dodge(width = 0.5), alpha = 0.7)+
  facet_wrap(~ education) +
  labs(title = "total activity by Sex in Each Education Category",
       x = "Age",
       y = "total_activity")
```


```{r}
#24-hour activity time course for each education level and gender
mean_min_by_sex_education <- participants_clean %>%
  group_by(sex, education) %>%
  summarise(across(starts_with("min"), mean, na.rm = TRUE))

mean_min_long <- mean_min_by_sex_education %>%
  pivot_longer(
    cols = starts_with("min"), 
    names_to = "minute", 
    names_prefix = 'min',
    values_to = 'mean'
  )%>%
  mutate(minute = as.numeric(minute))

ggplot(mean_min_long, mapping=aes(x=minute, y=mean, color=sex)) + geom_point(size=0.5) + theme_light() + facet_grid(.~ education) +
  geom_smooth(size=0.7) + scale_x_continuous(limits=c(0, 1440)) +
  scale_y_continuous(limits=c(0,18), breaks=seq(0,18, by=3)) + xlab("24-hour activity time courses") + ylab("mean acceleorometers value per minute") +
  ggtitle("Scatterplot of  the mean acceleorometers readings per minute against 24-hour activity ") + theme(legend.position = "bottom", plot.title=element_text(hjust=.5))
```


#Problem3


```{r}
#Import 4 datasets
Jan_2020 <- read_csv("Problem3/Jan 2020 Citi.csv",na = c("NA", "", ".","unknown"))%>%
  janitor::clean_names()%>%
  mutate(
    year = 2020, month = 'January')

Jan_2024 <- read_csv("Problem3/Jan 2024 Citi.csv",na = c("NA", "", ".","unknown"))%>%
  janitor::clean_names()%>%
  mutate(
    year = 2024, month = 'January')

July_2020 <- read_csv("Problem3/July 2020 Citi.csv",na = c("NA", "", ".","unknown"))%>%
  janitor::clean_names()%>%
  mutate(
    year = 2020, month = 'July')

July_2024 <- read_csv("Problem3/July 2024 Citi.csv",na = c("NA", "", ".","unknown"))%>%
  janitor::clean_names()%>%
  mutate(
    year = 2024, month = 'July')
```

```{r}
#merge 4 datasets
nyc_rider_df <- bind_rows(Jan_2020,July_2020,Jan_2024,July_2024)%>%
  relocate(year, month,.before = weekdays)
```

```{r}
#produce table showing total number of riders in each year and month seprating casual rider and member

total_rider <- nyc_rider_df%>%
  mutate(year_month = str_c(year,month,sep = "_"))%>%
  select(ride_id,year_month,member_casual)%>%
  group_by(year_month,member_casual)%>%
  summarize(count = n())

total_rider_table <- pivot_wider(
  total_rider,
  names_from = year_month,
  values_from = count)

knitr::kable(total_rider_table)
  
```

```{r}
#checking na in dataset July_2024
na_rows <- July_2024[!complete.cases(July_2024), ]

#Since several starting stations contain null value, I decided to drop na
July_2024_clean <- July_2024%>%
  drop_na(start_station_name)%>%
  select(ride_id,start_station_name)

#Create table showing 5 most popular starting stations for July 2024
July_2024_clean_table <- July_2024_clean%>%
  group_by(start_station_name)%>%
  summarize(count = n())%>%
  arrange(desc(count))
```


```{r}
#Create a table including day of the week,month,year, median ride duration

median_duration <- nyc_rider_df %>%
  mutate(weekdays = factor(weekdays, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  select(year, month, weekdays, duration) %>%
  group_by(year, month, weekdays) %>%
  summarise(median_duration = median(duration, na.rm = TRUE))

ggplot(median_duration,aes(x = weekdays, y = median_duration))+
  geom_point(aes(color = month),alpha = .5)+
  geom_smooth(se = FALSE)+
  facet_grid(.~year)+
  labs(title = "Median Ride Duration by Weekday, Month, and Year",
       x = "Day of the Week",
       y = "Median Ride Duration (minutes)",
       color = "Month")
```


```{r}
ggplot(median_duration, aes(x = weekdays, y = median_duration, fill = month)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ year) +
  labs(
    title = "Median Ride Duration by Day of the Week, Month, and Year",
    x = "Day of the Week",
    y = "Median Ride Duration (minutes)",
    fill = "Month"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

